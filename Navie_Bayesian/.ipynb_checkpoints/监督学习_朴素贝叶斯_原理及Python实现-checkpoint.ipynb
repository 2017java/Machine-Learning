{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1.-贝叶斯理论\" data-toc-modified-id=\"1.-贝叶斯理论-1\">1. 贝叶斯理论</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.1-贝叶斯定理[1]\" data-toc-modified-id=\"1.1-贝叶斯定理[1]-1.1\">1.1 贝叶斯定理<sup>[1]</sup></a></span></li><li><span><a href=\"#1.2-贝叶斯分类算法\" data-toc-modified-id=\"1.2-贝叶斯分类算法-1.2\">1.2 贝叶斯分类算法</a></span></li><li><span><a href=\"#1.3-朴素贝叶斯分类算法[2]\" data-toc-modified-id=\"1.3-朴素贝叶斯分类算法[2]-1.3\">1.3 朴素贝叶斯分类算法<sup><a href=\"https://blog.csdn.net/weixin_37352167/article/details/84867145\" target=\"_blank\">[2]</a></sup></a></span><ul class=\"toc-item\"><li><span><a href=\"#1.3.1-朴素贝叶斯分类器实例\" data-toc-modified-id=\"1.3.1-朴素贝叶斯分类器实例-1.3.1\">1.3.1 朴素贝叶斯分类器实例</a></span><ul class=\"toc-item\"><li><span><a href=\"#学习过程\" data-toc-modified-id=\"学习过程-1.3.1.1\">学习过程</a></span></li><li><span><a href=\"#预测过程\" data-toc-modified-id=\"预测过程-1.3.1.2\">预测过程</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#2-Python实现[3]\" data-toc-modified-id=\"2-Python实现[3]-2\">2 Python实现<sup><a href=\"https://blog.csdn.net/zhelong3205/article/details/78659169\" target=\"_blank\">[3]</a></sup></a></span><ul class=\"toc-item\"><li><span><a href=\"#2.1--拉普拉斯修正\" data-toc-modified-id=\"2.1--拉普拉斯修正-2.1\">2.1  拉普拉斯修正</a></span></li><li><span><a href=\"#2.2-对数变换\" data-toc-modified-id=\"2.2-对数变换-2.2\">2.2 对数变换</a></span></li></ul></li><li><span><a href=\"#参考资料\" data-toc-modified-id=\"参考资料-3\">参考资料</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 贝叶斯理论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 贝叶斯定理<sup>[1]</sup>\n",
    "\n",
    "贝叶斯定理旨在计算$P(A|B)$的值，也就是在已知B发生的条件下，A发生的概率是多少。大多数情况下，B是被观察事件，比如“昨天下雨了”，A为预测结果“今天会下雨”。\n",
    "\n",
    "对数据挖掘来说，B通常通常是`样本个数`，A为`被预测个体所属类别`\n",
    "\n",
    "贝叶斯定理公式入下：\n",
    "\n",
    "$$P(A|B)=\\frac{P(B|A)P(A)}{P(B)} \\tag{1} $$\n",
    "\n",
    "举例说明：我们想计算含有单词`money`的邮件为垃圾邮件的概率。\n",
    "\n",
    "* `P(A)`：在这里，A为“这是封垃圾邮件”。我们可以通过统计训练集中`垃圾邮件的比例`，得到`先验概率（prior probability）`：$P(A)$，如果我们的数据集每100封邮件有30封垃圾邮件，则$P(A)=0.3$。\n",
    "\n",
    "* `P(B)`：B表示“该邮件含有单词money”。类似地，我们通过计算`数据集中含有单词money的邮件比例`得到$P(B)$。如果每100封邮件中有10封邮件包含单词money，则$P(B)=0.1$。计算$P(B)$时，我们不关注邮件是不是垃圾邮件。\n",
    "\n",
    "* `P(B|A)`：指的是`垃圾邮件中含有单词money的概率`，通过统计训练集中所有垃圾邮件的数量以及其中含有单词money的数量。30封垃圾邮件中，如果有6封含有单词money，那么$P(B|A)=0.2$。\n",
    "\n",
    "* `P(A|B)`：因此可计算$P(A|B)=\\frac{P(B|A)P(A)}{P(B)}=\\frac{0.2\\times 0.3}{0.1}=0.6$，即`含有单词money的邮件为垃圾邮件的概率`为60%。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 贝叶斯分类算法\n",
    "贝叶斯分类算法，就是利用贝叶斯定理对数据进行分类。\n",
    "\n",
    "其基本表达式为：\n",
    "\n",
    "\\begin{align*}\n",
    "  y = arg \\max \\limits_{c_k} P(Y=c_k|X=x) &= \\frac{P(X=x|Y=c_k)P(Y=c_k)}{P(X=x)} \\tag{2}\n",
    "  \\\\\n",
    " &= \\frac{P(X=x|Y=c_k)P(Y=c_k)}{\\sum_{k}P(Y_k=c_k)P(X=x|Y=c_k)} \\tag{3}\n",
    " \\\\\n",
    "\\end{align*}\n",
    "\n",
    "其中：\n",
    "$$P(X=x|Y=c_k)P(Y=c_k)=P(x^{(1)}, x^{(2)},..., x^{(m)}|Y=c_k), k=1,2,...,n \\tag{4}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 朴素贝叶斯分类算法<sup>[[2]](https://blog.csdn.net/weixin_37352167/article/details/84867145)</sup>\n",
    "\n",
    "对于贝叶斯算法，其适用于只用一个特征的分类。当有多个特征时，由于特征之间不独立，因此$P(X=x|Y=c_k)$的计算非常复杂，假设$x$的第$j$特征$x^{(j)}$可取的值有$S_j$个，$Y$可取的值有$n$个，那么要计算的参数个数为$n\\times \\prod_{j=1}^mS_j$，对这样指数量级的参数进行估计是不实际的，所有有了朴素贝叶斯中的独立性假设。\n",
    "\n",
    "朴素贝叶斯算法在贝叶斯算法的基础上，多了两个默认的前提条件：\n",
    "1. `各个特征之间相互独立`\n",
    "2. 各个特征同等重要\n",
    "\n",
    "由独立性假设：\n",
    "\n",
    "\\begin{align*}\n",
    "  P(X=x|Y=c_k) &= P(x^{(1)}, x^{(2)},..., x^{(m)}|Y=c_k) \\tag{5}\n",
    " \\\\\n",
    " &= \\prod_{j=1}^mP(X^{(j)}=x^{(j)}|Y=c_k) \\quad(k=1,2,...,n) \\tag{6}\n",
    " \\\\\n",
    "\\end{align*}\n",
    "\n",
    "在独立性假设下，将原本指数级的参数数量变为常数级的$nS_j$个。\n",
    "\n",
    "由此有：\n",
    "\n",
    "\\begin{align*}\n",
    "  y = arg \\max \\limits_{c_k} P(Y=c_k|X=x)  &= \\frac{P(X=x|Y=c_k)P(Y=c_k)}{P(X=x)} \\tag{7}\n",
    "  \\\\\n",
    " &= \\frac{P(Y=c_k) \\prod_{j=1}^mP(X^{(j)}=x^{(j)}|Y=c_k)}{P(X=x)} \\tag{8}\n",
    " \\\\\n",
    "\\end{align*}\n",
    "\n",
    "注意到，分母对于所有$c_k$都是相同的。\n",
    "\n",
    "因此到朴素贝叶斯算法的基本表达式：\n",
    "\\begin{align*}\n",
    "  y =  &= arg \\max \\limits_{c_k} P(Y=c_k) \\prod_{j=1}^mP(X^{(j)}=x^{(j)}|Y=c_k) \\quad(k=1,2,...,n) \\tag{9}\n",
    "  \\\\\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 朴素贝叶斯分类器实例\n",
    "\n",
    "预测某人是否拖欠贷款($Y: {c_1=yes,c_2=no}$)\n",
    "\n",
    "$x^{(1)}$有房 | $x^{(2)}$年收入 | $Y$拖欠   \n",
    "-|-|-\n",
    "是 | 125k | no |\n",
    "否 | 100k | no |\n",
    "否 | 70k | no |\n",
    "是 | 120k | no |\n",
    "否 | 95k | yes |\n",
    "否 | 60k | no |\n",
    "是 | 220k | no |\n",
    "否 | 85k | yes |\n",
    "否 | 75k | no |\n",
    "否 | 90k | yes |\n",
    "\n",
    "#### 学习过程\n",
    "\n",
    "* 计算先验分布：\n",
    "\n",
    "    $P(Y=yes)= \\frac{3}{10}$，$P(Y=no)= \\frac{7}{10}$\n",
    "\n",
    "\n",
    "* 对于$x^{(1)}$有房，计算条件分布：\n",
    "\n",
    "    $P(有房 = 是 |Y=yes)= 0$，$P(有房=是|Y=no)= \\frac{3}{7}$\n",
    "\n",
    "    $P(有房 = 否 |Y=yes)= 1$，$P(有房=否|Y=no)= \\frac{4}{7}$\n",
    "\n",
    "\n",
    "* 对于$x^{(2)}$收入，计算条件分布：\n",
    "年收入可视为连续值，在此先离散化，后计算概率：（${低：年收入 \\leq 90k，中：年收入 \\leq 150k，高：年收入 \\ge 150k}$）\n",
    "\n",
    "    $P(年收入 = 高 |Y=yes)= 0$，$P(年收入 = 高|Y=no)= \\frac{1}{7}$\n",
    "\n",
    "    $P(年收入 = 中 |Y=yes)= \\frac{1}{3}$，$P(年收入 = 中|Y=no)= \\frac{3}{7}$\n",
    "\n",
    "    $P(年收入 = 低 |Y=yes)= \\frac{1}{2}$，$P(年收入 = 低|Y=no)= \\frac{3}{7}$\n",
    "    \n",
    "#### 预测过程\n",
    "\n",
    "假设预测样本$x_*={有房=否，年收入=110k}$，预测$x_*$是否有可能拖欠贷款\n",
    "\n",
    "根据模型表达式：$y = arg \\max \\limits_{c_k} P(Y=c_k) \\prod_{j=1}^mP(X^{(j)}=x^{(j)}|Y=c_k)$\n",
    "\n",
    "* 计算：\n",
    "\n",
    "    $P(Y=no|X=x_*)=P(Y=no)P(有房=否|Y=no)P(年收入=中|Y=no)= \\frac{7}{10} \\times \\frac{4}{7} \\times \\frac{3}{7}= \\frac{12}{70}$\n",
    "\n",
    "    $P(Y=yes|X=x_*)=P(Y=yes)P(有房=否|Y=yes)P(年收入=中|Y=yes)= \\frac{3}{10} \\times 1 \\times \\frac{1}{3}= \\frac{7}{70}$\n",
    "\n",
    "    因此$ y = arg \\max \\limits_{c_k} \\{P(Y=no|X=x_*), P(Y=yes|X=x_*)\\} = \\frac{12}{70}$\n",
    "\n",
    "    所以$x_*$的类别为no，即不会拖欠贷款。\n",
    "\n",
    "\n",
    "* $P(Y=no|X=x_*), P(Y=yes|X=x_*)$ 和并不等于1，这是因为计算过程省略了分母$P(X=x)$。\n",
    "\n",
    "    归一化后各自概率为：\n",
    "\n",
    "    $P(Y=no|X=x_*)=63.16 \\%$\n",
    "\n",
    "    $P(Y=yes|X=x_*)=36.84 \\%$\n",
    "    \n",
    "    即有63.16%的概率认为$x_*$的类别为no。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Python实现<sup>[[3]](https://blog.csdn.net/zhelong3205/article/details/78659169)</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1  拉普拉斯修正\n",
    "\n",
    "* 为什么需要修正：因为我们的样本集有限，对于某些离散的值可能并没有出现，这样会导致概率的乘积为0，影响最终分类结果。\n",
    "\n",
    "* 拉普拉斯修正法：对于一个离散的值，我们在使用的时候不是直接输出它的概率，而是对概率值进行“平滑”处理。即默认所有特征都出现过一次，将概率该为下面的形式：\n",
    "\n",
    "    $P(c)= \\frac{|D_c|+1}{|D|+N} \\tag{9}$\n",
    "\n",
    "    $P(x_i|c)= \\frac{|D_{c,x_i}|+1}{|D_c|+N_i} \\tag{10}$\n",
    "    \n",
    "    其中$N$是全体特征的总数，$D$为这一类的总数目，这就避免了概率值为0的情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 对数变换\n",
    "\n",
    "由于计算概率时需要对很多歌很小的概率值做乘法，所以有可能出现下溢的情况，所以我们可以对概率的乘积取自然对数，根据自然对数函数的单调性，不会改变最终的大小，同时也防止了下溢出现的问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import math\n",
    "# 使用词集法进行贝叶斯分类\n",
    "# 构造数据集,分类是侮辱性 or 非侮辱性\n",
    "def loadDataset () :\n",
    "    postingList=[['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'],\n",
    "                 ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n",
    "                 ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],\n",
    "                 ['stop', 'posting', 'stupid', 'worthless', 'garbage'],\n",
    "                 ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],\n",
    "                 ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]\n",
    "    classVec = [0,1,0,1,0,1]    #1 is abusive, 0 not\n",
    "    return postingList, classVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个包涵所有词汇的列表 , 为后面建立词条向量使用\n",
    "def createlist (dataset) :\n",
    "    vovabset = set ([])\n",
    "    for vec in dataset :\n",
    "        vovabset = vovabset | set (vec)\n",
    "    return list (vovabset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将词条转化为向量的形式\n",
    "def changeword2vec (inputdata, wordlist) :\n",
    "    returnVec = [0] * len (wordlist)\n",
    "    for word in inputdata :\n",
    "        if word in wordlist :\n",
    "            returnVec[wordlist.index(word)] = 1\n",
    "    return returnVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建贝叶斯分类器 \n",
    "def trainNBO (dataset, classlebels) :\n",
    "    num_of_sample = len (dataset)\n",
    "    num_of_feature = len (dataset[0])\n",
    "    pAusuive = sum (classlebels) / num_of_sample # 侮辱性语言的概率\n",
    "    p0Num = np.ones (num_of_feature)\n",
    "    p1Num = np.ones (num_of_feature)\n",
    "    p0tot = num_of_feature\n",
    "    p1tot = num_of_feature\n",
    "    for i in range (num_of_sample) :\n",
    "        if classlebels[i] == 1 :\n",
    "            p1Num += dataset[i]\n",
    "            p1tot += sum (dataset[i])\n",
    "        else :\n",
    "            p0Num += dataset[i]\n",
    "            p0tot += sum (dataset[i])   \n",
    "    p0Vec = p0Num / p0tot\n",
    "    p1Vec = p1Num / p1tot\n",
    "    for i in range (num_of_feature) :\n",
    "        p0Vec[i] = math.log (p0Vec[i])\n",
    "        p1Vec[i] = math.log (p1Vec[i])\n",
    "    return p0Vec, p1Vec, pAusuive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  定义分类器 \n",
    "def classifyNB(vec2Classify, p0Vec, p1Vec, pClass1):\n",
    "    p1 = sum(vec2Classify * p1Vec) + log(pClass1)    #element-wise mult\n",
    "    p0 = sum(vec2Classify * p0Vec) + log(1.0 - pClass1)\n",
    "    if p1 > p0:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['please', 'problems', 'ate', 'is', 'flea', 'maybe', 'love', 'food', 'him', 'take', 'has', 'help', 'my', 'cute', 'stupid', 'dalmation', 'posting', 'worthless', 'steak', 'so', 'licks', 'quit', 'to', 'dog', 'not', 'how', 'park', 'garbage', 'mr', 'stop', 'buying', 'I']\n",
      "[1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[-3.33220451 -3.33220451 -3.33220451 -3.33220451 -3.33220451 -4.02535169\n",
      " -3.33220451 -4.02535169 -2.9267394  -4.02535169 -3.33220451 -3.33220451\n",
      " -2.63905733 -3.33220451 -4.02535169 -3.33220451 -4.02535169 -4.02535169\n",
      " -3.33220451 -3.33220451 -3.33220451 -4.02535169 -3.33220451 -3.33220451\n",
      " -4.02535169 -3.33220451 -4.02535169 -4.02535169 -3.33220451 -3.33220451\n",
      " -4.02535169 -3.33220451]\n",
      "[-3.93182563 -3.93182563 -3.93182563 -3.93182563 -3.93182563 -3.23867845\n",
      " -3.93182563 -3.23867845 -3.23867845 -3.23867845 -3.93182563 -3.93182563\n",
      " -3.93182563 -3.93182563 -2.54553127 -3.93182563 -3.23867845 -2.83321334\n",
      " -3.93182563 -3.93182563 -3.93182563 -3.23867845 -3.23867845 -2.83321334\n",
      " -3.23867845 -3.93182563 -3.23867845 -3.23867845 -3.93182563 -3.23867845\n",
      " -3.23867845 -3.93182563]\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# 测试代码 \n",
    "dataset,classlebels = loadDataset ()\n",
    "wordlist = createlist (dataset)\n",
    "print (wordlist)\n",
    "print (changeword2vec (dataset[0], wordlist))\n",
    "trainmat = []\n",
    "for temp in dataset :\n",
    "    trainmat.append (changeword2vec (temp,wordlist))\n",
    "p0V, p1V, pAb = trainNBO (trainmat, classlebels)\n",
    "print (p0V)\n",
    "print (p1V)\n",
    "print (pAb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考资料\n",
    "\n",
    "[1] Robert Layton，杜春晓. Python数据挖掘入门与实践[M]. 北京: 人民邮电出版社, 2016: 93-103.\n",
    "\n",
    "[2] GoWeiXH.机器学习 - 朴素贝叶斯（下）- 朴素贝叶斯分类器[EB/OL].https://blog.csdn.net/weixin_37352167/article/details/84867145, 2018-02-06.\n",
    "\n",
    "[3] Glory_g.贝叶斯分类器以及Python实现[EB/OL].https://blog.csdn.net/zhelong3205/article/details/78659169, 2017-11-28."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
