{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1.-信息熵-Information-Entropy\" data-toc-modified-id=\"1.-信息熵-Information-Entropy-1\">1. 信息熵 Information Entropy</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.1-信息熵公式推导\" data-toc-modified-id=\"1.1-信息熵公式推导-1.1\">1.1 信息熵公式推导</a></span></li></ul></li><li><span><a href=\"#2.-信息增益-Information-Gain\" data-toc-modified-id=\"2.-信息增益-Information-Gain-2\">2. 信息增益 Information Gain</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.1-信息增益最大化\" data-toc-modified-id=\"2.1-信息增益最大化-2.1\">2.1 信息增益最大化</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.1.1-利用离散特征进行分类\" data-toc-modified-id=\"2.1.1-利用离散特征进行分类-2.1.1\">2.1.1 利用离散特征进行分类</a></span></li><li><span><a href=\"#2.1.2-利用连续特征进行分类\" data-toc-modified-id=\"2.1.2-利用连续特征进行分类-2.1.2\">2.1.2 利用连续特征进行分类</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.1.2.1-二分法\" data-toc-modified-id=\"2.1.2.1-二分法-2.1.2.1\">2.1.2.1 二分法</a></span></li><li><span><a href=\"#2.1.2.2-信息熵、信息增益及二分法的Python实现\" data-toc-modified-id=\"2.1.2.2-信息熵、信息增益及二分法的Python实现-2.1.2.2\">2.1.2.2 信息熵、信息增益及二分法的Python实现</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#参考资料\" data-toc-modified-id=\"参考资料-3\">参考资料</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 信息熵 Information Entropy \n",
    "\n",
    "\n",
    "信息是个很抽象的概念。人们常常说信息很多，或者信息较少，但却很难说清楚信息到底有多少。比如一本五十万字的中文书到底有多少信息量。直到1948年，香农提出了“信息熵”的概念，才解决了对信息的量化度量问题。\n",
    "\n",
    "`信息熵`这个词是香农从热力学中借用过来的。热力学中的热熵是表示分子状态混乱程度的物理量。香农用信息熵的概念来`描述不确定性`。\n",
    "\n",
    "* 随机变量$x$的信息熵计算公式：$H(x)= -\\sum_{i=1}^nP(x_i)log_2(P_i)$\n",
    "* 信息熵越大，则表示不确定性越高。\n",
    "* 在文本中，当不同的词汇越多时，其信息熵越大，直观上来说就是所包含的信息越多\n",
    "\n",
    ">熵：在物理的热力学中，用熵来表示分子状态混乱程度。当一个物体温度越高时，其内部粒子活动越剧烈，也越混乱。因此混乱程度越高，熵越大。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 信息熵公式推导\n",
    "\n",
    "\n",
    "1. 计算取出结果与原顺序相同的概率：\n",
    "\n",
    "$$P(x_i)=P(x_1)\\times P(x_2) \\times...\\times P(x_n)\\tag{1}$$\n",
    "\n",
    "2. 将概率公式取以2为底的对数变换，得到信息量$I(x_i)$的公式：\n",
    "\n",
    "$$I(x_i)=log_2(\\frac{1}{P(x_i)})=-log_2(P(x_i))\\tag{2}$$\n",
    "\n",
    "3. 随机变量$x$的信息熵计算公式：: \n",
    "\n",
    "$$H(x)=E[I(x_i)]=-E[log_2(P(x_i))]= -\\sum_{i=1}^nP(x_i)log_2(P_i)\\tag{3}$$\n",
    "\n",
    "对于样本集合$D$来说，随机变量$x$是样本的类别，即假设样本有$k$个类别，样本总数为$D$，则类别$i$的概率是$\\frac{c_i}{D}$。\n",
    "\n",
    "因此样本集合$D$的经验熵为：\n",
    "$$H(D)=-\\sum_{i=1}^k \\frac{|c_i|}{|D|}log_2(\\frac{|c_i|}{|D|}) \\tag{4}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例1：假设有四个球，从中随机放回地抽出四个球，下面计算各个事件的信息熵：\n",
    "\n",
    "1.`红红红红`，则事件$x$的信息熵：\n",
    "\n",
    "$H(x)=-\\sum_{i=1}^4P(x_i)log_2(P_i)\n",
    "=[1 \\times log_2(1)+1 \\times log_2(1)+1 \\times log_2(1)+1 \\times log_2(1)]=0$\n",
    "\n",
    "2.`红红红蓝`，则事件$y$的信息熵：\n",
    "\n",
    "$H(y)=-\\sum_{i=1}^4P(y_i)log_2(P_i)\n",
    "=[0.75 \\times log_2(0.75)+0.75 \\times log_2(0.75)+0.75 \\times log_2(0.75)+0.25 \\times log_2(0.25)]=1.4338$\n",
    "\n",
    "3.`红红蓝蓝`，则事件$z$的信息熵：\n",
    "\n",
    "$H(z)=-\\sum_{i=1}^4P(z_i)log_2(P_i)\n",
    "=[0.5 \\times log_2(0.5)+0.5 \\times log_2(0.5)+0.5 \\times log_2(0.5)+0.5 \\times log_2(0.5)]=2$\n",
    "\n",
    "由上面三个例子可以看出，当混乱程度越高时，信息熵越大。\n",
    "\n",
    "关于各类熵的定义及推导，可参考[这篇文章](https://blog.csdn.net/Tomcater321/article/details/80699044)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 信息增益 Information Gain\n",
    "\n",
    "**信息增益：**\n",
    "\n",
    "对于待划分的数据集$D$，其信息熵大小是固定的，但是划分后子代熵之和是不定的。子代熵越小说明使用此特征划分得到的子集不确定性越小（纯度越高），因此`父代与子代的信息熵之差`（`信息增益`）越大，说明使用当前特征划分数据集$D$时，其纯度上升的更快。<sup>[1] \n",
    "\n",
    "\n",
    "**与决策树关系：**\n",
    "\n",
    "我们在构建最优的决策树时总希望能够快速到达村度更高的集合，这一点可以参考优化算法中的梯度下降（每一步沿着负梯度方法最小化损失函数使函数值快速减小）同理，在决策树构建的过程中我们总是希望集合往最快到达纯度更高的子集合方向发展，因此我们总是选择使得信息增益最大的特征来划分当前数据集$D$。\n",
    "\n",
    "使用特征$A$划分数据集$D$，计算划分前后各个数据集的信息熵，并计算`信息增益`：\n",
    "\n",
    "$$g(D,A)=H(D)-H(D|A) \\tag{5}$$\n",
    "\n",
    "其中，假设特征$A$将数据集$D$划分为$n$个子代，则$H(D|A)$为划分后子代的平均信息熵：\n",
    "\n",
    "$$H(D|A)= \\sum_{i=1}^nP(A_i)H(A_i) \\tag{6}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例2：假设我们在调查性别与活跃度哪一个对用户流失影响越大。<sup>[[2]](https://blog.csdn.net/it_beecoder/article/details/79554388)\n",
    "    \n",
    "样本如下：\n",
    "\n",
    "Gender | Activation | is_lost  \n",
    "-|-|-\n",
    "M | H | 0 |\n",
    "F | M | 0 |\n",
    "M | L | 1 |\n",
    "F | H | 0 |\n",
    "M | H | 0 |\n",
    "M | M | 0 |\n",
    "M | M | 1 |\n",
    "F | M | 0 |\n",
    "F | L | 1 |\n",
    "F | M | 0 |\n",
    "F | H | 0 |\n",
    "M | L | 1 |\n",
    "F | L | 0 |\n",
    "M | H | 0 |\n",
    "M | H | 0 |\n",
    "\n",
    "**按性别分类：**\n",
    "\n",
    " \\ | Lost | No-lost | Sum\n",
    "-|-|-|-\n",
    " Whole | 5 | 10 | 15\n",
    " Male | 3 | 5 | 8 \n",
    " Female | 2 | 5 | 7 \n",
    "\n",
    "整体熵：\n",
    "\n",
    "$E(S)=-[\\frac{5}{15}log_2(\\frac{5}{15})+\\frac{10}{15}log_2(\\frac{10}{15})]=0.9182$\n",
    "\n",
    "性别熵：\n",
    "\n",
    "$E(g_1)=-[\\frac{3}{8}log_2(\\frac{3}{8})+\\frac{5}{8}log_2(\\frac{5}{8})]=0.0.9543$\n",
    "\n",
    "$E(g_2)=-[\\frac{2}{7}log_2(\\frac{2}{7})+\\frac{2}{7}log_2(\\frac{2}{7})]=0.8631$\n",
    "\n",
    "`性别信息增益`：\n",
    "$g(S|g)=E(S)-\\frac{8}{15}E(g_1)-\\frac{7}{15}E(g_2)=0.0064$\n",
    "\n",
    "\n",
    "**按活跃度分类**\n",
    "\n",
    " \\ | Lost | No-lost | Sum\n",
    "-|-|-|-\n",
    " Whole | 5 | 10 | 15\n",
    " Hight | 0 | 6 | 6 \n",
    " Mid | 1 | 4 | 5 \n",
    " Low | 4 | 0 | 4 \n",
    " \n",
    "活跃度熵：\n",
    "\n",
    "$E(a_1)=0$\n",
    "\n",
    "$E(a_2)=0.7219$\n",
    "\n",
    "$E(a_2)=0$\n",
    "\n",
    "`活跃度信息增益`：\n",
    "$g(S|a)=E(S)-\\frac{6}{15}E(a_1)-\\frac{5}{15}E(a_2)-\\frac{4}{15}E(a_3)=0.0064$\n",
    "\n",
    "活跃度信息增益比性别信息增益大，也就是说，活跃度对用户流失的影响比性别大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 信息增益最大化\n",
    "\n",
    "### 2.1.1 利用离散特征进行分类\n",
    "\n",
    "1. 计算父代熵\n",
    "2. 计算子代熵\n",
    "3. 计算信息增益，按信息增益较大的进行分类\n",
    "4. 如果分类后结果不理想，可将其分类作为父代继续进行分类\n",
    "\n",
    "例3：仍以上面的例子为例，之前，我们已经计算出了活跃度对于用户流失的影响较大，当用户的活跃度为Hight时，用户流失为0，当用户活跃度为Low时，用户全部流失，因此可以得到：\n",
    "\n",
    "<img src=\"https://x1a-alioss.oss-cn-shenzhen.aliyuncs.com/Screen Shot 2019-08-06 at 14.07.28.png\" width=\"520\" >\n",
    "\n",
    "可以看到，Hight和Low组的信息熵为0，纯度已达到最高；但是Mid组纯度未达到最高，因此以Mid组的数据作为父代，重复例2的过程，由于例2数据只有两个特征，因此只能尝试使用性别分类；若例2数据有2个以上特征，则此时可以重复例2过程，计算其余特征的信息增益，并选取信息增益最大的特征作为分类依据。`由此也可以看出，离散特征决策树的最大深度不超过其特征数`（连续特征决策树的特征可多次使用）。\n",
    "\n",
    "下面尝试使用性别分组，Mid组的样本：\n",
    "\n",
    "Gender | Activation | is_lost  \n",
    "-|-|-\n",
    "F | M | 0 |\n",
    "M | M | 0 |\n",
    "M | M | 1 |\n",
    "F | M | 0 |\n",
    "F | M | 0 |\n",
    "\n",
    "对Mid组使用性别分类后的结果：\n",
    "\n",
    "<img  src=\"https://x1a-alioss.oss-cn-shenzhen.aliyuncs.com/Screen Shot 2019-08-06 at 14.20.18.png\" width=\"420\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 利用连续特征进行分类\n",
    "\n",
    "#### 2.1.2.1 二分法\n",
    "因为连续特征属性的可取值数目不再有限，因此不能像前面处理离散属性一样枚举离散属性来对节点进行划分，因此需要对连续属性离散化。\n",
    "\n",
    "常用的离散化策略是二分法：\n",
    "\n",
    "给定训练集$D$和连续属性$a$，假定$a$在$D$上出现了$n$个不同的取值，先把这些值从小到达排序，记为$\\{a^1,a^2,...,a^n\\}$，基于划分点$t$可以将$D$分为子集$D_t^-$和$D_t^+$，其中$D_t^-$是包含那些属性$a$上取值不大于$t$的样本，$D_t^+$则包含哪些在属性$a$上取值大于$t$的样本。显然，对相邻的属性取值$a^i$与$a^{i+1}$来说，$t$在区间$[a^i,a^{i+1})$中取任意值所产生的划分结果相同。因此，对连续属性$a$，我们可考虑包含$n-1$个元素的候选划分点集合：\n",
    "\n",
    "$$T_a=\\{ \\frac{a^i+a^{i+1}}{2} \\} \\quad (1 \\leq i \\leq n-1) \\tag{7}$$\n",
    "\n",
    "\n",
    "   即把区间$[a^i,a^{i+1})$的中位点$\\frac{a^i+a^{i+1}}{2}$作为候选划分点，然后就可以像前面处理离散属性值那样来考虑这些划分点，并选择最后的划分点进行样本集合的划分，使用的公式如下：\n",
    "\n",
    "$$g(D,a)=\\max \\limits_{t\\in T_a}g(D,a,t)\n",
    "=\\max \\limits_{t\\in T_a} \\{E(D)-\\sum_{\\lambda \\in(-,+)} \\frac{|D_t^\\lambda|}{|D|}log_2(\\frac{|D_t^\\lambda|}{|D|})\\}\n",
    "\\tag{8}$$\n",
    "\n",
    "其中$g(D,a,t)$是样本集$D$基于划分点$t$二分后的信息增益。\n",
    "划分的时候，选择使$g(D,a,t)$最大的划分点。<sup>[[3]](https://blog.csdn.net/u012328159/article/details/79396893)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### 2.1.2.2 信息熵、信息增益及二分法的Python实现\n",
    "例4：下面以周志华《机器学习》---[西瓜数据集3.0](https://github.com/tz28/machine-learning/blob/master/西瓜数据集3.0.txt) 为例，计算特征“密度”的最佳划分点以及其信息增益，数据如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>编号</th>\n",
       "      <th>色泽</th>\n",
       "      <th>根蒂</th>\n",
       "      <th>敲声</th>\n",
       "      <th>纹理</th>\n",
       "      <th>脐部</th>\n",
       "      <th>触感</th>\n",
       "      <th>密度</th>\n",
       "      <th>含糖率</th>\n",
       "      <th>好瓜</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>青绿</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>浊响</td>\n",
       "      <td>清晰</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>乌黑</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>沉闷</td>\n",
       "      <td>清晰</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>乌黑</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>浊响</td>\n",
       "      <td>清晰</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.264</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>青绿</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>沉闷</td>\n",
       "      <td>清晰</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.318</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>浅白</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>浊响</td>\n",
       "      <td>清晰</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.215</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>青绿</td>\n",
       "      <td>稍蜷</td>\n",
       "      <td>浊响</td>\n",
       "      <td>清晰</td>\n",
       "      <td>稍凹</td>\n",
       "      <td>软粘</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>乌黑</td>\n",
       "      <td>稍蜷</td>\n",
       "      <td>浊响</td>\n",
       "      <td>稍糊</td>\n",
       "      <td>稍凹</td>\n",
       "      <td>软粘</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>乌黑</td>\n",
       "      <td>稍蜷</td>\n",
       "      <td>浊响</td>\n",
       "      <td>清晰</td>\n",
       "      <td>稍凹</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.211</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>乌黑</td>\n",
       "      <td>稍蜷</td>\n",
       "      <td>沉闷</td>\n",
       "      <td>稍糊</td>\n",
       "      <td>稍凹</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>青绿</td>\n",
       "      <td>硬挺</td>\n",
       "      <td>清脆</td>\n",
       "      <td>清晰</td>\n",
       "      <td>平坦</td>\n",
       "      <td>软粘</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>浅白</td>\n",
       "      <td>硬挺</td>\n",
       "      <td>清脆</td>\n",
       "      <td>模糊</td>\n",
       "      <td>平坦</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>浅白</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>浊响</td>\n",
       "      <td>模糊</td>\n",
       "      <td>平坦</td>\n",
       "      <td>软粘</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>青绿</td>\n",
       "      <td>稍蜷</td>\n",
       "      <td>浊响</td>\n",
       "      <td>稍糊</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>浅白</td>\n",
       "      <td>稍蜷</td>\n",
       "      <td>沉闷</td>\n",
       "      <td>稍糊</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>乌黑</td>\n",
       "      <td>稍蜷</td>\n",
       "      <td>浊响</td>\n",
       "      <td>清晰</td>\n",
       "      <td>稍凹</td>\n",
       "      <td>软粘</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>浅白</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>浊响</td>\n",
       "      <td>模糊</td>\n",
       "      <td>平坦</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>青绿</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>沉闷</td>\n",
       "      <td>稍糊</td>\n",
       "      <td>稍凹</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    编号  色泽  根蒂  敲声  纹理  脐部  触感     密度    含糖率  好瓜\n",
       "0    1  青绿  蜷缩  浊响  清晰  凹陷  硬滑  0.697  0.460   1\n",
       "1    2  乌黑  蜷缩  沉闷  清晰  凹陷  硬滑  0.774  0.376   1\n",
       "2    3  乌黑  蜷缩  浊响  清晰  凹陷  硬滑  0.634  0.264   1\n",
       "3    4  青绿  蜷缩  沉闷  清晰  凹陷  硬滑  0.608  0.318   1\n",
       "4    5  浅白  蜷缩  浊响  清晰  凹陷  硬滑  0.556  0.215   1\n",
       "5    6  青绿  稍蜷  浊响  清晰  稍凹  软粘  0.403  0.237   1\n",
       "6    7  乌黑  稍蜷  浊响  稍糊  稍凹  软粘  0.481  0.149   1\n",
       "7    8  乌黑  稍蜷  浊响  清晰  稍凹  硬滑  0.437  0.211   1\n",
       "8    9  乌黑  稍蜷  沉闷  稍糊  稍凹  硬滑  0.666  0.091   0\n",
       "9   10  青绿  硬挺  清脆  清晰  平坦  软粘  0.243  0.267   0\n",
       "10  11  浅白  硬挺  清脆  模糊  平坦  硬滑  0.245  0.057   0\n",
       "11  12  浅白  蜷缩  浊响  模糊  平坦  软粘  0.343  0.099   0\n",
       "12  13  青绿  稍蜷  浊响  稍糊  凹陷  硬滑  0.639  0.161   0\n",
       "13  14  浅白  稍蜷  沉闷  稍糊  凹陷  硬滑  0.657  0.198   0\n",
       "14  15  乌黑  稍蜷  浊响  清晰  稍凹  软粘  0.360  0.370   0\n",
       "15  16  浅白  蜷缩  浊响  模糊  平坦  硬滑  0.593  0.042   0\n",
       "16  17  青绿  蜷缩  沉闷  稍糊  稍凹  硬滑  0.719  0.103   0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"Data/Watermelon_Data.txt\")\n",
    "df['好瓜'] = df['好瓜'].map({'是':1, '否':0})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 以数据集中的`“密度”`为例，决策树开始学习时，根节点包含的17个训练样本在属性上取值均不同。我们把“密度”这些值从小到大排序："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.243, 0.245, 0.343, 0.36, 0.403, 0.437, 0.481, 0.556, 0.593, 0.608, 0.634, 0.639, 0.657, 0.666, 0.697, 0.719, 0.774]\n"
     ]
    }
   ],
   "source": [
    "Density_arr = df['密度'].sort_values()\n",
    "f = lambda x: round(x,3) # 保留三位小数\n",
    "Density_arr = Density_arr.apply(f)\n",
    "print(Density_arr.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 根据公式(7)计算分割点$T_a$："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.244, 0.294, 0.352, 0.382, 0.42, 0.459, 0.518, 0.575, 0.601, 0.621, 0.637, 0.648, 0.661, 0.681, 0.708, 0.746]\n"
     ]
    }
   ],
   "source": [
    "T_midu = (Density_arr+Density_arr.shift(-1))/2\n",
    "T_midu = T_midu[:-1].apply(f) # 二分法获得的（n-1）个分割点\n",
    "T_midu.index=np.arange(len(T_midu))\n",
    "print(T_midu.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 计算父代信息熵（Ent_D）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以西瓜质量划分集合\n",
    "def divide_arr(arr):\n",
    "    arr = df['好瓜'].iloc[arr.index.values.tolist()]\n",
    "    arr_len = len(arr)\n",
    "    Left_len = sum(arr == 1)\n",
    "    Right_len = arr_len - Left_len\n",
    "    return arr_len, Left_len, Right_len\n",
    "\n",
    "# 计算集合信息熵\n",
    "def entropy(arr):\n",
    "    arr_len, Left_len, Right_len = divide_arr(arr)\n",
    "    L_frac = Left_len/arr_len\n",
    "    R_frac = Right_len/arr_len\n",
    "    if L_frac==0:\n",
    "        Ent = -(R_frac*np.log2(R_frac))\n",
    "    elif R_frac==0:\n",
    "        Ent = -(L_frac*np.log2(L_frac))\n",
    "    else:\n",
    "        Ent = -(L_frac*np.log2(L_frac) + R_frac*np.log2(R_frac))\n",
    "    Ent = round(Ent,3)\n",
    "    return Ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.998"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ent_D = entropy(Density_arr)\n",
    "Ent_D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 利用第2步获得的分割点，计算(n-1)种分法对应的子代信息熵（gen_entropy_arr）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用分割点二分父代\n",
    "def binary(arr, node):\n",
    "    arr_L = arr[arr<=node]\n",
    "    arr_L.name = 'arr_L'\n",
    "    arr_R = arr[arr>node]\n",
    "    arr_R.name = 'arr_R'\n",
    "    return arr_L, arr_R\n",
    "\n",
    "# 计算子代熵\n",
    "def gen_entropy(arr, node):\n",
    "    arr_L, arr_R = binary(arr, node)\n",
    "    len_L = len(arr_L)\n",
    "    len_R = len(arr_R)\n",
    "    len_D = len_L + len_R\n",
    "    Ent_gen = len_L/len_D*entropy(arr_L) + len_R/len_D*entropy(arr_R)\n",
    "    Ent_gen = round(Ent_gen,3)\n",
    "    return Ent_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_entropy_arr = pd.Series(np.empty(len(T_midu)))\n",
    "for i, cut in enumerate(T_midu):\n",
    "    gen_entropy_arr.iloc[i] =  gen_entropy(Density_arr, cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 计算各类分法的信息增益："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>划分点</th>\n",
       "      <th>子集熵</th>\n",
       "      <th>信息增益</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.244</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.294</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.352</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.382</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.420</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.459</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.518</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.575</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.601</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.621</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.637</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.648</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.661</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.681</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.708</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.746</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      划分点    子集熵   信息增益\n",
       "0   0.244  0.941  0.057\n",
       "1   0.294  0.880  0.118\n",
       "2   0.352  0.811  0.187\n",
       "3   0.382  0.735  0.263\n",
       "4   0.420  0.904  0.094\n",
       "5   0.459  0.967  0.031\n",
       "6   0.518  0.994  0.004\n",
       "7   0.575  0.995  0.003\n",
       "8   0.601  0.995  0.003\n",
       "9   0.621  0.994  0.004\n",
       "10  0.637  0.967  0.031\n",
       "11  0.648  0.991  0.007\n",
       "12  0.661  0.997  0.001\n",
       "13  0.681  0.973  0.025\n",
       "14  0.708  0.997  0.001\n",
       "15  0.746  0.931  0.067"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.concat([T_midu, gen_entropy_arr], axis=1)\n",
    "df2.columns=['划分点','子集熵']\n",
    "df2['信息增益'] = Ent_D - df2['子集熵']\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 因此信息增益最大值为0.263，对应划分点为0.382，如下所示:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "划分点     0.382\n",
      "子集熵     0.735\n",
      "信息增益    0.263\n",
      "Name: 3, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df2.iloc[df2['信息增益'].idxmax()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "继续对其他的特征进行以上步骤，可以得到其他特征的信息增益，因此该连续特征的决策树的第一个分割点为信息增益最大的特征所对应的分割点。\n",
    "\n",
    "下面是本数据集中各特征的信息增益值：<sup>[[4]](https://blog.csdn.net/u012328159/article/details/70184415)\n",
    "\n",
    "$g(D|色泽)=0.109 \\quad g(D|根蒂)=0.143$\n",
    "\n",
    "$g(D|敲声)=0.141 \\quad g(D|纹理)=0.381$\n",
    "\n",
    "$g(D|脐部)=0.289 \\quad g(D|触感)=0.006$\n",
    "\n",
    "$g(D|密度)=0.262 \\quad g(D|含糖率)=0.349$\n",
    "\n",
    "由此可见，“纹理”的信息增益量值最大，因此”纹理“被选作根节点划分属性。只要重复以上过程，就能构造出一颗决策树：\n",
    "\n",
    "<img src=\"https://x1a-alioss.oss-cn-shenzhen.aliyuncs.com/Screen Shot 2019-08-06 at 21.22.29.png\" width=\"520\" >\n",
    "\n",
    "需要注意的是：与离散属性不同，若当前节点划分属性为连续属性，该属性还可以作为其后代节点的划分属性。如下图的一颗决策树，“含糖率”这个属性在根节点用了一次，后代节点也用了一次，只是两次划分点取值不同。\n",
    "\n",
    "<img src=\"https://x1a-alioss.oss-cn-shenzhen.aliyuncs.com/Screen Shot 2019-08-06 at 21.26.59.png\" width=\"520\" >\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考资料\n",
    "\n",
    "[1] Tomcater321.决策树--信息增益，信息增益比，Geni指数的理解\n",
    "[EB/OL].https://blog.csdn.net/Tomcater321/article/details/80699044, 2018-06-14.\n",
    "\n",
    "[2] It_BeeCoder.机器学习中信息增益的计算方法 [EB/OL].https://blog.csdn.net/it_beecoder/article/details/79554388, 2018-03-14.\n",
    "\n",
    "[3] 天泽28.决策树（decision tree）(三)——连续值处理 [EB/OL].https://blog.csdn.net/u012328159/article/details/79396893, 2018-02-28.\n",
    "\n",
    "[4] 天泽28.决策树（decision tree）(一)——构造决策树方法 [EB/OL].https://blog.csdn.net/u012328159/article/details/70184415, 2017-04-18."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "248px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
