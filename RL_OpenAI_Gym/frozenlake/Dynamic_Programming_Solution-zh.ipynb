{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 迷你项目：动态规划\n",
    "\n",
    "在此 notebook 中，你将自己编写很多经典动态规划算法的实现。\n",
    "\n",
    "虽然我们提供了一些起始代码，但是你可以删掉这些提示并从头编写代码。\n",
    "\n",
    "### 第 0 部分：探索 FrozenLakeEnv\n",
    "\n",
    "请使用以下代码单元格创建 [FrozenLake](https://github.com/openai/gym/blob/master/gym/envs/toy_text/frozen_lake.py) 环境的实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frozenlake import FrozenLakeEnv\n",
    "\n",
    "env = FrozenLakeEnv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "智能体将会在 $4 \\times 4$ 网格世界中移动，状态编号如下所示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Python\n",
    "[[ 0  1  2  3]\n",
    " [ 4  5  6  7]\n",
    " [ 8  9 10 11]\n",
    " [12 13 14 15]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "智能体可以执行 4 个潜在动作："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Python\n",
    "LEFT = 0\n",
    "DOWN = 1\n",
    "RIGHT = 2\n",
    "UP = 3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，$\\mathcal{S}^+ = \\{0, 1, \\ldots, 15\\}$ 以及 $\\mathcal{A} = \\{0, 1, 2, 3\\}$。请通过运行以下代码单元格验证这一点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(16)\n",
      "Discrete(4)\n",
      "16\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# print the state space and action space\n",
    "print(env.observation_space)\n",
    "print(env.action_space)\n",
    "\n",
    "# print the total number of states and actions\n",
    "print(env.nS)\n",
    "print(env.nA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "动态规划假设智能体完全了解 MDP。我们已经修改了 `frozenlake.py` 文件以使智能体能够访问一步动态特性。  \n",
    "\n",
    "请执行以下代码单元格以返回特定状态和动作对应的一步动态特性。具体而言，当智能体在网格世界中以状态 1 向左移动时，`env.P[1][0]` 会返回每个潜在奖励的概率和下一个状态。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.3333333333333333, 1, 0.0, False),\n",
       " (0.3333333333333333, 0, 0.0, False),\n",
       " (0.3333333333333333, 5, 0.0, True)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.P[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个条目的格式如下所示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prob, next_state, reward, done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中：\n",
    "- `prob` 详细说明了相应的  (`next_state`, `reward`) 对的条件概率，以及\n",
    "- 如果 `next_state` 是终止状态，则 `done` 是 `True` ，否则是 `False`。\n",
    "\n",
    "因此，我们可以按照以下方式解析 `env.P[1][0]`：\n",
    "$$\n",
    "\\mathbb{P}(S_{t+1}=s',R_{t+1}=r|S_t=1,A_t=0) = \\begin{cases}\n",
    "               \\frac{1}{3} \\text{ if } s'=1, r=0\\\\\n",
    "               \\frac{1}{3} \\text{ if } s'=0, r=0\\\\\n",
    "               \\frac{1}{3} \\text{ if } s'=5, r=0\\\\\n",
    "               0 \\text{ else}\n",
    "            \\end{cases}\n",
    "$$\n",
    "\n",
    "你可以随意更改上述代码单元格，以探索在其他（状态、动作）对下环境的行为是怎样的。\n",
    "\n",
    "### 第 1 部分：迭代策略评估\n",
    "\n",
    "在此部分，你将自己编写迭代策略评估的实现。\n",
    "\n",
    "你的算法应该有四个**输入**参数：\n",
    "- `env`：这是 OpenAI Gym 环境的实例，其中 `env.P` 会返回一步动态特性。\n",
    "- `policy`：这是一个二维 numpy 数组，其中 `policy.shape[0]` 等于状态数量 (`env.nS`) ， `policy.shape[1]` 等于动作数量 (`env.nA`) 。`policy[s][a]`  返回智能体在状态 `s` 时根据该策略选择动作 `a` 的概率。\n",
    "- `gamma`：这是折扣率。它必须是在 0 到 1（含）之间的值，默认值为：`1`。\n",
    "- `theta`：这是一个非常小的正数，用于判断估算值是否足够地收敛于真值函数 (默认值为：`1e-8`）。\n",
    "\n",
    "该算法会返回以下**输出结果**：\n",
    "- `V`：这是一个一维numpy数组，其中 `V.shape[0]` 等于状态数量 (`env.nS`)。`V[s]` 包含状态 `s` 在输入策略下的估算值。\n",
    "\n",
    "请完成以下代码单元格中的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def policy_evaluation(env, policy, gamma=1, theta=1e-8):\n",
    "    V = np.zeros(env.nS)\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for s in range(env.nS):\n",
    "            Vs = 0\n",
    "            for a, action_prob in enumerate(policy[s]):\n",
    "                for prob, next_state, reward, done in env.P[s][a]:\n",
    "                    Vs += action_prob * prob * (reward + gamma * V[next_state])\n",
    "            delta = max(delta, np.abs(V[s]-Vs))\n",
    "            V[s] = Vs\n",
    "        if delta < theta:\n",
    "            break\n",
    "    return V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将评估等概率随机策略  $\\pi$，其中对于所有 $s\\in\\mathcal{S}$ 和 $a\\in\\mathcal{A}(s)$ ，$\\pi(a|s) = \\frac{1}{|\\mathcal{A}(s)|}$。  \n",
    "\n",
    "请使用以下代码单元格在变量 `random_policy`中指定该策略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_policy = np.ones([env.nS, env.nA]) / env.nA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行下个代码单元格以评估等概率随机策略并可视化输出结果。状态值函数已调整形状，以匹配网格世界的形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plot_utils import plot_values\n",
    "\n",
    "# evaluate the policy \n",
    "V = policy_evaluation(env, random_policy)\n",
    "\n",
    "plot_values(V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](output_13_0.png)\n",
    "\n",
    "\n",
    "运行以下代码单元格以测试你的函数。如果代码单元格返回 **PASSED**，则表明你正确地实现了该函数！  \n",
    "\n",
    "**注意：**为了确保结果准确，确保你的 `policy_evaluation` 函数满足上文列出的要求（具有四个输入、一个输出，并且没有更改输入参数的默认值）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**<span style=\"color: green;\">PASSED</span>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import check_test\n",
    "\n",
    "check_test.run_check('policy_evaluation_check', policy_evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color: green;\">PASSED</span>**\n",
    "\n",
    "\n",
    "### 第 2 部分：通过 $v_\\pi$ 获取 $q_\\pi$\n",
    "\n",
    "在此部分，你将编写一个函数，该函数的输入是状态值函数估值以及一些状态 $s\\in\\mathcal{S}$。它会返回输入状态 $s\\in\\mathcal{S}$ 对应的**动作值函数中的行**。即你的函数应同时接受输入 $v_\\pi$ 和 $s$，并针对所有 $a\\in\\mathcal{A}(s)$ 返回 $q_\\pi(s,a)$。\n",
    "\n",
    "你的算法应该有四个**输入**参数：\n",
    "- `env`：这是 OpenAI Gym 环境的实例，其中 `env.P` 会返回一步动态特性。\n",
    "- `V`：这是一个一维 numpy 数组，其中 `V.shape[0]` 等于状态数量 (`env.nS`)。`V[s]` 包含状态 `s` 的估值。\n",
    "- `s`：这是环境中的状态对应的整数。它应该是在 `0` 到 `(env.nS)-1`（含）之间的值。\n",
    "- `gamma`：这是折扣率。它必须是在 0 到 1（含）之间的值，默认值为：`1`。\n",
    "\n",
    "该算法会返回以下**输出结果**：\n",
    "- `q`：这是一个一维 numpy 数组，其中 `q.shape[0]` 等于动作数量 (`env.nA`)。`q[a]` 包含状态 `s` 和动作 `a` 的（估算）值。\n",
    "\n",
    "请完成以下代码单元格中的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_from_v(env, V, s, gamma=1):\n",
    "    q = np.zeros(env.nA)\n",
    "    for a in range(env.nA):\n",
    "        for prob, next_state, reward, done in env.P[s][a]:\n",
    "            q[a] += prob * (reward + gamma * V[next_state])\n",
    "    return q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请运行以下代码单元格以输出上述状态值函数对应的动作值函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action-Value Function:\n",
      "[[0.0147094  0.01393978 0.01393978 0.01317015]\n",
      " [0.00852356 0.01163091 0.0108613  0.01550788]\n",
      " [0.02444514 0.02095298 0.02406033 0.01435346]\n",
      " [0.01047649 0.01047649 0.00698432 0.01396865]\n",
      " [0.02166487 0.01701828 0.01624865 0.01006281]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.05433538 0.04735105 0.05433538 0.00698432]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.01701828 0.04099204 0.03480619 0.04640826]\n",
      " [0.07020885 0.11755991 0.10595784 0.05895312]\n",
      " [0.18940421 0.17582037 0.16001424 0.04297382]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.08799677 0.20503718 0.23442716 0.17582037]\n",
      " [0.25238823 0.53837051 0.52711478 0.43929118]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "Q = np.zeros([env.nS, env.nA])\n",
    "for s in range(env.nS):\n",
    "    Q[s] = q_from_v(env, V, s)\n",
    "print(\"Action-Value Function:\")\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行以下代码单元格以测试你的函数。如果代码单元格返回 **PASSED**，则表明你正确地实现了该函数！  \n",
    "\n",
    "**注意：**为了确保结果准确，确保 `q_from_v` 函数满足上文列出的要求（具有四个输入、一个输出，并且没有更改输入参数的默认值）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**<span style=\"color: green;\">PASSED</span>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_test.run_check('q_from_v_check', q_from_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color: green;\">PASSED</span>**\n",
    "\n",
    "\n",
    "### 第 3 部分：策略改进\n",
    "\n",
    "在此部分，你将自己编写策略改进实现。 \n",
    "\n",
    "你的算法应该有三个**输入**参数：\n",
    "- `env`：这是 OpenAI Gym 环境的实例，其中 `env.P` 会返回一步动态特性。\n",
    "- `V`：这是一个一维 numpy 数组，其中 `V.shape[0]` 等于状态数量 (`env.nS`)。`V[s]` 包含状态 `s` 的估值。\n",
    "- `gamma`：这是折扣率。它必须是在 0 到 1（含）之间的值，默认值为：`1`。\n",
    "\n",
    "该算法会返回以下**输出结果**：\n",
    "- `policy`：这是一个二维 numpy 数组，其中 `policy.shape[0]` 等于状态数量 (`env.nS`) ， `policy.shape[1]` 等于动作数量 (`env.nA`) 。`policy[s][a]`  返回智能体在状态 `s` 时根据该策略选择动作 `a` 的概率。\n",
    "\n",
    "请完成以下代码单元格中的函数。建议你使用你在上文实现的 `q_from_v` 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_improvement(env, V, gamma=1):\n",
    "    policy = np.zeros([env.nS, env.nA]) / env.nA\n",
    "    for s in range(env.nS):\n",
    "        q = q_from_v(env, V, s, gamma)\n",
    "        \n",
    "        # OPTION 1: construct a deterministic policy \n",
    "        # policy[s][np.argmax(q)] = 1\n",
    "        \n",
    "        # OPTION 2: construct a stochastic policy that puts equal probability on maximizing actions\n",
    "        best_a = np.argwhere(q==np.max(q)).flatten()\n",
    "        policy[s] = np.sum([np.eye(env.nA)[i] for i in best_a], axis=0)/len(best_a)\n",
    "        \n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行以下代码单元格以测试你的函数。如果代码单元格返回 **PASSED**，则表明你正确地实现了该函数！  \n",
    "\n",
    "**注意：**为了确保结果准确，确保 `policy_improvement` 函数满足上文列出的要求（具有三个输入、一个输出，并且没有更改输入参数的默认值）。\n",
    "\n",
    "在继续转到该 notebook 的下个部分之前，强烈建议你参阅 **Dynamic_Programming_Solution.ipynb** 中的解决方案。该函数有很多正确的实现方式！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**<span style=\"color: green;\">PASSED</span>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_test.run_check('policy_improvement_check', policy_improvement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color: green;\">PASSED</span>**\n",
    "\n",
    "\n",
    "### 第 4 部分：策略迭代\n",
    "\n",
    "在此部分，你将自己编写策略迭代的实现。该算法会返回最优策略，以及相应的状态值函数。\n",
    "\n",
    "你的算法应该有三个**输入**参数：\n",
    "- `env`：这是 OpenAI Gym 环境的实例，其中 `env.P` 会返回一步动态特性。\n",
    "- `gamma`：这是折扣率。它必须是在 0 到 1（含）之间的值，默认值为：`1`。\n",
    "- `theta`：这是一个非常小的正数，用于判断策略评估步骤是否足够地收敛于真值函数 (默认值为：`1e-8`）。\n",
    "\n",
    "该算法会返回以下**输出结果**：\n",
    "- `policy`：这是一个二维 numpy 数组，其中 `policy.shape[0]` 等于状态数量 (`env.nS`) ， `policy.shape[1]` 等于动作数量 (`env.nA`) 。`policy[s][a]`  返回智能体在状态 `s` 时根据该策略选择动作 `a` 的概率。\n",
    "- `V`：这是一个一维 numpy 数组，其中 `V.shape[0]` 等于状态数量 (`env.nS`)。`V[s]` 包含状态 `s` 的估值。\n",
    "\n",
    "请完成以下代码单元格中的函数。强烈建议你使用你在上文实现的 `policy_evaluation` 和 `policy_improvement` 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def policy_iteration(env, gamma=1, theta=1e-8):\n",
    "    policy = np.ones([env.nS, env.nA]) / env.nA\n",
    "    while True:\n",
    "        V = policy_evaluation(env, policy, gamma, theta)\n",
    "        new_policy = policy_improvement(env, V)\n",
    "        \n",
    "        # OPTION 1: stop if the policy is unchanged after an improvement step\n",
    "        if (new_policy == policy).all():\n",
    "            break;\n",
    "        \n",
    "        # OPTION 2: stop if the value function estimates for successive policies has converged\n",
    "        # if np.max(abs(policy_evaluation(env, policy) - policy_evaluation(env, new_policy))) < theta*1e2:\n",
    "        #    break;\n",
    "        \n",
    "        policy = copy.copy(new_policy)\n",
    "    return policy, V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行下个代码单元格以解决该 MDP 并可视化输出结果。最优状态值函数已调整形状，以匹配网格世界的形状。\n",
    "\n",
    "**将该最优状态值函数与此 notebook 第 1 部分的状态值函数进行比较**。_最优状态值函数一直都大于或等于等概率随机策略的状态值函数吗？_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the optimal policy and optimal state-value function\n",
    "policy_pi, V_pi = policy_iteration(env)\n",
    "\n",
    "# print the optimal policy\n",
    "print(\"\\nOptimal Policy (LEFT = 0, DOWN = 1, RIGHT = 2, UP = 3):\")\n",
    "print(policy_pi,\"\\n\")\n",
    "\n",
    "plot_values(V_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimal Policy (LEFT = 0, DOWN = 1, RIGHT = 2, UP = 3):\n",
    "[[ 1.    0.    0.    0.  ]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 1.    0.    0.    0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.5   0.    0.5   0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 0.    1.    0.    0.  ]\n",
    " [ 1.    0.    0.    0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.    0.    1.    0.  ]\n",
    " [ 0.    1.    0.    0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](output_29_1.png)\n",
    "\n",
    "\n",
    "运行以下代码单元格以测试你的函数。如果代码单元格返回 **PASSED**，则表明你正确地实现了该函数！  \n",
    "\n",
    "**注意：**为了确保结果准确，确保 `policy_iteratio` 函数满足上文列出的要求（具有三个输入、两个输出，并且没有更改输入参数的默认值）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_test.run_check('policy_iteration_check', policy_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color: green;\">PASSED</span>**\n",
    "\n",
    "\n",
    "### 第 5 部分：截断策略迭代\n",
    "\n",
    "在此部分，你将自己编写截断策略迭代的实现。  \n",
    "\n",
    "首先，你将实现截断策略评估。你的算法应该有五个**输入**参数：\n",
    "- `env`：这是 OpenAI Gym 环境的实例，其中 `env.P` 会返回一步动态特性。\n",
    "- `policy`：这是一个二维 numpy 数组，其中 `policy.shape[0]` 等于状态数量 (`env.nS`) ， `policy.shape[1]` 等于动作数量 (`env.nA`) 。`policy[s][a]`  返回智能体在状态 `s` 时根据该策略选择动作 `a` 的概率。\n",
    "- `V`：这是一个一维 numpy 数组，其中 `V.shape[0]` 等于状态数量 (`env.nS`)。`V[s]` 包含状态 `s` 的估值。\n",
    "- `max_it`：这是一个正整数，对应的是经历状态空间的次数（默认值为：`1`）。\n",
    "- `gamma`：这是折扣率。它必须是在 0 到 1（含）之间的值，默认值为：`1`。\n",
    "\n",
    "该算法会返回以下**输出结果**：\n",
    "- `V`：这是一个一维 numpy 数组，其中 `V.shape[0]` 等于状态数量 (`env.nS`)。`V[s]` 包含状态 `s` 的估值。\n",
    "\n",
    "请完成以下代码单元格中的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncated_policy_evaluation(env, policy, V, max_it=1, gamma=1):\n",
    "    num_it=0\n",
    "    while num_it < max_it:\n",
    "        for s in range(env.nS):\n",
    "            v = 0\n",
    "            q = q_from_v(env, V, s, gamma)\n",
    "            for a, action_prob in enumerate(policy[s]):\n",
    "                v += action_prob * q[a]\n",
    "            V[s] = v\n",
    "        num_it += 1\n",
    "    return V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着，你将实现截断策略迭代。你的算法应该接受五个**输入**参数：\n",
    "- `env`：这是 OpenAI Gym 环境的实例，其中 `env.P` 会返回一步动态特性。\n",
    "- `max_it`：这是一个正整数，对应的是经历状态空间的次数（默认值为：`1`）。\n",
    "- `gamma`：这是折扣率。它必须是在 0 到 1（含）之间的值，默认值为：`1`。\n",
    "- `theta`：这是一个非常小的正整数，用作停止条件（默认值为：`1e-8`）。\n",
    "\n",
    "该算法会返回以下**输出结果**：\n",
    "- `policy`：这是一个二维 numpy 数组，其中 `policy.shape[0]` 等于状态数量 (`env.nS`) ， `policy.shape[1]` 等于动作数量 (`env.nA`) 。`policy[s][a]`  返回智能体在状态 `s` 时根据该策略选择动作 `a` 的概率。\n",
    "- `V`：这是一个一维 numpy 数组，其中 `V.shape[0]` 等于状态数量 (`env.nS`)。`V[s]` 包含状态 `s` 的估值。\n",
    "\n",
    "请完成以下代码单元格中的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncated_policy_iteration(env, max_it=1, gamma=1, theta=1e-8):\n",
    "    V = np.zeros(env.nS)\n",
    "    policy = np.zeros([env.nS, env.nA]) / env.nA\n",
    "    while True:\n",
    "        policy = policy_improvement(env, V)\n",
    "        old_V = copy.copy(V)\n",
    "        V = truncated_policy_evaluation(env, policy, V, max_it, gamma)\n",
    "        if max(abs(V-old_V)) < theta:\n",
    "            break;\n",
    "    return policy, V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行下个代码单元格以解决该 MDP 并可视化输出结果。状态值函数已调整形状，以匹配网格世界的形状。\n",
    "\n",
    "请实验不同的 `max_it` 参数值。始终都能获得最优状态值函数吗？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_tpi, V_tpi = truncated_policy_iteration(env, max_it=2)\n",
    "\n",
    "# print the optimal policy\n",
    "print(\"\\nOptimal Policy (LEFT = 0, DOWN = 1, RIGHT = 2, UP = 3):\")\n",
    "print(policy_tpi,\"\\n\")\n",
    "\n",
    "# plot the optimal state-value function\n",
    "plot_values(V_tpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimal Policy (LEFT = 0, DOWN = 1, RIGHT = 2, UP = 3):\n",
    "[[ 1.    0.    0.    0.  ]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 1.    0.    0.    0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.5   0.    0.5   0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 0.    1.    0.    0.  ]\n",
    " [ 1.    0.    0.    0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.    0.    1.    0.  ]\n",
    " [ 0.    1.    0.    0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](output_37_1.png)\n",
    "\n",
    "\n",
    "运行以下代码单元格以测试你的函数。如果代码单元格返回 **PASSED**，则表明你正确地实现了该函数！ \n",
    "\n",
    "**注意：**为了确保结果准确，确保 `truncated_policy_iteration` 函数满足上文列出的要求（具有四个输入、两个输出，并且没有更改输入参数的默认值）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_test.run_check('truncated_policy_iteration_check', truncated_policy_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color: green;\">PASSED</span>**\n",
    "\n",
    "\n",
    "### 第 6 部分：值迭代\n",
    "\n",
    "在此部分，你将自己编写值迭代的实现。\n",
    "\n",
    "你的算法应该接受三个输入参数：\n",
    "- `env`：这是 OpenAI Gym 环境的实例，其中 `env.P` 会返回一步动态特性。\n",
    "- `gamma`：这是折扣率。它必须是在 0 到 1（含）之间的值，默认值为：`1`。 \n",
    "- `theta`：这是一个非常小的正整数，用作停止条件（默认值为：`1e-8`）。\n",
    "\n",
    "该算法会返回以下**输出结果**：\n",
    "- `policy`：这是一个二维 numpy 数组，其中 `policy.shape[0]` 等于状态数量 (`env.nS`) ， `policy.shape[1]` 等于动作数量 (`env.nA`) 。`policy[s][a]`  返回智能体在状态 `s` 时根据该策略选择动作 `a` 的概率。\n",
    "- `V`：这是一个一维 numpy 数组，其中 `V.shape[0]` 等于状态数量 (`env.nS`)。`V[s]` 包含状态 `s` 的估值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(env, gamma=1, theta=1e-8):\n",
    "    V = np.zeros(env.nS)\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for s in range(env.nS):\n",
    "            v = V[s]\n",
    "            V[s] = max(q_from_v(env, V, s, gamma))\n",
    "            delta = max(delta,abs(V[s]-v))\n",
    "        if delta < theta:\n",
    "            break\n",
    "    policy = policy_improvement(env, V, gamma)\n",
    "    return policy, V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行下个代码单元格以解决该 MDP 并可视化输出结果。状态值函数已调整形状，以匹配网格世界的形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_vi, V_vi = value_iteration(env)\n",
    "\n",
    "# print the optimal policy\n",
    "print(\"\\nOptimal Policy (LEFT = 0, DOWN = 1, RIGHT = 2, UP = 3):\")\n",
    "print(policy_vi,\"\\n\")\n",
    "\n",
    "# plot the optimal state-value function\n",
    "plot_values(V_vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimal Policy (LEFT = 0, DOWN = 1, RIGHT = 2, UP = 3):\n",
    "[[ 1.    0.    0.    0.  ]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 1.    0.    0.    0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.5   0.    0.5   0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 0.    1.    0.    0.  ]\n",
    " [ 1.    0.    0.    0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.    0.    1.    0.  ]\n",
    " [ 0.    1.    0.    0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](output_43_1.png)\n",
    "\n",
    "\n",
    "运行以下代码单元格以测试你的函数。如果代码单元格返回 **PASSED**，则表明你正确地实现了该函数！ \n",
    "\n",
    "**注意：**为了确保结果准确，确保 `truncated_policy_iteration` 函数满足上文列出的要求（具有三个输入、两个输出，并且没有更改输入参数的默认值）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_test.run_check('value_iteration_check', value_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color: green;\">PASSED</span>**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
